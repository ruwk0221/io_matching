{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "atomic-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))\n",
    "import jReversion as jR\n",
    "from LDOI import BooleanDOI_processing as BDOIp\n",
    "from LDOI import qm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import concurrent.futures\n",
    "import par_helper as ph\n",
    "import random\n",
    "import robustness as rb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abandoned-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkModel =[ 'bortezomib',\n",
    "                # 'igvh',\n",
    "                'apoptosis',\n",
    "                # 'aurora',\n",
    "                #'bt474_long',\n",
    "                'bt474_short',\n",
    "                # 'cd4t',\n",
    "                'colitis',\n",
    "                'death',\n",
    "                # 'egfr',\n",
    "                # 'erbb',\n",
    "                # 'fa_brca',\n",
    "                # 'fa_check',\n",
    "                #'hcc1954_long',\n",
    "                'hcc1954_short',\n",
    "                'hgf',\n",
    "                'mammalian',\n",
    "                # 'mammalian_2006',\n",
    "                'mapk',\n",
    "                'oxidative',\n",
    "                # 'pro_inflammatory',\n",
    "                'fibroblasts',\n",
    "                #'skbr3_long',\n",
    "                'skbr3_short',\n",
    "                'tlgl_2008',\n",
    "                'tlgl_2011',\n",
    "                # 'tlgl_2011_reduced',\n",
    "                # 'prostate',\n",
    "                'migration'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "first-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canalizing_chain(g, model_name, prefix='n', suffix='n'):\n",
    "    gcopy = g.copy()\n",
    "    gcopy.remove_edges_from(nx.selfloop_edges(gcopy))\n",
    "    read_nodes = list(gcopy)\n",
    "    \n",
    "    mapping = {}  # nodename to number index\n",
    "    inverse_mapping = {}  # number index to nodename\n",
    "    read_nodes_dict = {}\n",
    "    inverse_read_nodes_dict = {}\n",
    "    for i, node in enumerate(read_nodes):\n",
    "        index = prefix + str(i) + suffix\n",
    "        mapping[str(node)] = index\n",
    "        inverse_mapping[index] = str(node)\n",
    "        mapping['~' + str(node)] = '~' + index\n",
    "        inverse_mapping['~' + index] = '~' + str(node)\n",
    "        read_nodes_dict[i] = str(node)\n",
    "        inverse_read_nodes_dict[str(node)] = i\n",
    "\n",
    "    input_nodes = [node for node in gcopy.nodes if gcopy.in_degree(node) == 0]\n",
    "    output_nodes = [node for node in gcopy.nodes if gcopy.out_degree(node) == 0]\n",
    "\n",
    "    num_inputs = len(input_nodes)\n",
    "    num_input_conditions = 2 ** num_inputs\n",
    "    input_conditions = np.ndarray((num_inputs, 2), dtype=object)\n",
    "    for idx, input_node in enumerate(input_nodes):\n",
    "        input_conditions[idx, 0] = '~' + str(input_node)\n",
    "        input_conditions[idx, 1] = str(input_node)\n",
    "\n",
    "\n",
    "    output_nodes_ex = []\n",
    "    output_nodes_ex.extend([read_nodes_dict[idx] for idx in output_nodes])\n",
    "    output_nodes_ex.extend(['~'+read_nodes_dict[idx] for idx in output_nodes])\n",
    "    input_nodes_ex = input_conditions.reshape(num_inputs * 2, ).tolist()\n",
    "    try:\n",
    "        GExpanded = nx.read_gml('../networks/' + model_name+ '_expanded_network.gml')\n",
    "    except IOError:\n",
    "        GExpanded = ph.par_get_expanded_network(gcopy, prefix=prefix, suffix=suffix, worker=num_worker)\n",
    "           \n",
    "    \n",
    "        \n",
    "    GEx_nonComposite = GExpanded.copy()\n",
    "    GEx_nonComposite.remove_nodes_from([node for node in GEx_nonComposite.nodes if node.find('_') > -1])\n",
    "    \n",
    "    wccs_size = [len(c) for c in sorted(nx.weakly_connected_components(GEx_nonComposite), key=len, reverse=True)]\n",
    "    \n",
    "    return {\n",
    "        'num_wccs': len(wccs_size),\n",
    "        'norm_num_wccs': len(wccs_size)/float(len(GEx_nonComposite)),\n",
    "        'len_largest_wcc': wccs_size[0],\n",
    "        'norm_len_largest_wcc': wccs_size[0] / float(len(g)),\n",
    "        'avg_len_wcc': np.average(wccs_size)\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complete-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd = pd.DataFrame(columns=['model', 'num_wccs', 'norm_num_wccs', 'len_largest_wcc',  'norm_len_largest_wcc', 'avg_len_wcc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "separated-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bortezomib: DONE\n",
      "apoptosis: DONE\n",
      "bt474_short: DONE\n",
      "colitis: DONE\n",
      "death: DONE\n",
      "hcc1954_short: DONE\n",
      "hgf: DONE\n",
      "mammalian: DONE\n",
      "mapk: DONE\n",
      "oxidative: DONE\n",
      "fibroblasts: DONE\n",
      "skbr3_short: DONE\n",
      "tlgl_2008: DONE\n",
      "tlgl_2011: DONE\n",
      "migration: DONE\n"
     ]
    }
   ],
   "source": [
    "for Model in networkModel:\n",
    "    Prefix, Suffix = 'n', 'n'\n",
    "    TEMP = jR.cellcollective(Model, Prefix, Suffix, directory='../')\n",
    "\n",
    "    BooleanRuleFileName = TEMP['BooleanRule_filename']\n",
    "    network_name = TEMP['network_name']\n",
    "\n",
    "    NumInputs = TEMP['num_inputs']\n",
    "    NumInputConditions = TEMP['num_input_conditions']\n",
    "\n",
    "    InputConditions = TEMP['input_conditions']\n",
    "\n",
    "    OutputNodes = TEMP['output_nodes']\n",
    "    InputNodes = TEMP['input_nodes']\n",
    "\n",
    "    Mapping = TEMP['mapping']\n",
    "    InverseMapping = TEMP['inverse_mapping']\n",
    "    GRead = TEMP['Gread']\n",
    "    ReadNodes = TEMP['read_nodes']\n",
    "    \n",
    "    temp = canalizing_chain(g=GRead, model_name=Model)\n",
    "\n",
    "\n",
    "    temp['model'] = Model\n",
    "    result_pd = result_pd.append(temp, ignore_index=True)\n",
    "\n",
    "    print(Model + ': DONE')\n",
    "# configuration_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swiss-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_csv('../data/cc_canalizing_chain_ori.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
