{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "athletic-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))\n",
    "import networkx as nx\n",
    "import random\n",
    "import jReversion as jR\n",
    "import robustness as rb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import par_helper as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_boolean_network_er_kauffman(n=30, p=0.3, bias=0.5):\n",
    "    '''\n",
    "\n",
    "    The code is originated from the read_ndetwork() by Colin Campbell.\n",
    "    '''\n",
    "    def clean_states(x):\n",
    "        #cleans binary representation of node input states\n",
    "        out=x[2:]                                                               # Strip leading 0b\n",
    "        return '0'*(len(inf)-len(out))+out                                      # Append leading 0's as needed\n",
    "\n",
    "    while True:\n",
    "        g = nx.generators.random_graphs.gnp_random_graph(n=n, p=p, directed=True)\n",
    "        \n",
    "        input_node = [node for node in g.nodes if g.in_degree(node) == 0]\n",
    "        output_node = [node for node in g.nodes if g.out_degree(node) == 0]\n",
    "        if len(input_node) == 0:              # at least one input node\n",
    "            random_node = random.randrange(n)\n",
    "            g.remove_edges_from(list(g.in_edges(random_node)))\n",
    "            input_node = [node for node in g.nodes if g.in_degree(node) == 0]\n",
    "            \n",
    "        if len(output_node) == 0:            # at least one output node\n",
    "            random_node = random.randrange(n)\n",
    "            g.remove_edges_from(list(g.out_edges(random_node)))\n",
    "            output_node = [node for node in g.nodes if g.out_degree(node) == 0]\n",
    "        \n",
    "        if len(g.subgraph(input_node + output_node).edges) > 0: continue # output nodes are connected to input nodes\n",
    "                    \n",
    "        if nx.is_weakly_connected(g): break\n",
    "\n",
    "    for n in g.nodes:\n",
    "        inf = list(g.predecessors(n))\n",
    "        if len(inf) > 0: \n",
    "            g.nodes[n]['update_nodes'] = inf.copy()\n",
    "            g.nodes[n]['update_rules'] = {}\n",
    "\n",
    "            bool_states = map(bin,range(2**len(inf)))\n",
    "            bool_states = map(clean_states,bool_states)\n",
    "            for j in bool_states:\n",
    "                g.nodes[n]['update_rules'][j] = int(random.random() < bias)    # Store outcome for every possible input\n",
    "        else:\n",
    "#             g.add_edge(n, n)\n",
    "            g.nodes[n]['update_nodes'] = [n]\n",
    "            g.nodes[n]['update_rules'] = {'0': 0, '1': 1}\n",
    "\n",
    "    return g,list(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incredible-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['network_idx', 'size_of_network', 'num_link', 'C0', 'C1', 'C2', 'C3', 'robustness_pa', 'robustness_ip', 'redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "removed-variable",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-71:\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-73:\n",
      "Process ForkProcess-72:\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-75:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/jijoo/miniconda3/envs/theor/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b83f0bae1f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0minput_nodes_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_conditions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mGExpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_get_expanded_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_of_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     TempGIOW = jR.get_input_output_relation(GExpanded, mapping, inverse_mapping, input_conditions, output_nodes_ex,\n\u001b[1;32m     40\u001b[0m                                             constant_nodes=[])\n",
      "\u001b[0;32m~/tmp/pycharm_project_225/par_helper.py\u001b[0m in \u001b[0;36mpar_get_expanded_network\u001b[0;34m(Gread, prefix, suffix, equal_sign, worker)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_get_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_sign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/theor/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/theor/lib/python3.8/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread_wakeup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/theor/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/theor/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_networks = 100\n",
    "size_of_network = 20\n",
    "link_probability = 0.1\n",
    "sampling_num = 10\n",
    "num_of_worker = 5\n",
    "prefix, suffix = 'n', 'n'\n",
    "for network_idx in range(num_of_networks):\n",
    "    g, read_nodes = gen_random_boolean_network_er_kauffman(n=size_of_network, p=link_probability)\n",
    "    mapping = {}  # nodename to number index\n",
    "    inverse_mapping = {}  # number index to nodename\n",
    "    read_nodes_dict = {}\n",
    "    inverse_read_nodes_dict = {}\n",
    "    for i, node in enumerate(read_nodes):\n",
    "        index = prefix + str(i) + suffix\n",
    "        mapping[str(node)] = index\n",
    "        inverse_mapping[index] = str(node)\n",
    "        mapping['~' + str(node)] = '~' + index\n",
    "        inverse_mapping['~' + index] = '~' + str(node)\n",
    "        read_nodes_dict[i] = str(node)\n",
    "        inverse_read_nodes_dict[str(node)] = i\n",
    "    \n",
    "    input_nodes = [node for node in g.nodes if g.in_degree(node) == 0]\n",
    "    output_nodes = [node for node in g.nodes if g.out_degree(node) == 0]\n",
    "    \n",
    "    num_inputs = len(input_nodes)\n",
    "    num_input_conditions = 2 ** num_inputs\n",
    "    input_conditions = np.ndarray((num_inputs, 2), dtype=object)\n",
    "    for idx, input_node in enumerate(input_nodes):\n",
    "        input_conditions[idx, 0] = '~' + str(input_node)\n",
    "        input_conditions[idx, 1] = str(input_node)\n",
    "    \n",
    "    \n",
    "    output_nodes_ex = []\n",
    "    output_nodes_ex.extend([read_nodes_dict[idx] for idx in output_nodes])\n",
    "    output_nodes_ex.extend(['~'+read_nodes_dict[idx] for idx in output_nodes])\n",
    "    input_nodes_ex = input_conditions.reshape(num_inputs * 2, ).tolist()\n",
    "    \n",
    "    GExpanded = ph.par_get_expanded_network(g, prefix='n', suffix='n', worker=num_of_worker)\n",
    "    TempGIOW = jR.get_input_output_relation(GExpanded, mapping, inverse_mapping, input_conditions, output_nodes_ex,\n",
    "                                            constant_nodes=[])\n",
    "    LDOIs = TempGIOW['LDOIs']\n",
    "    GeneLDOIs = TempGIOW['gene_LDOIs']\n",
    "    Conflicts = TempGIOW['conflicts']\n",
    "    GeneConflicts = TempGIOW['gene_conflicts']\n",
    "    IORelation = TempGIOW['io_relation']\n",
    "    GRemained = TempGIOW['G_remained']\n",
    "\n",
    "    R0 = jR.identifying_r0_mutations_ldoi(GExpanded, output_nodes_ex, mapping, inverse_mapping, input_conditions, IORelation)\n",
    "    # DM = jR.identifying_disconnecting_mutations(GExpanded, InputNodes, OutputNodes, Mapping, InverseMapping)\n",
    "    R1 = jR.identifying_r1_mutations_ldoi(GExpanded, output_nodes_ex, mapping, inverse_mapping, input_conditions, IORelation)\n",
    "#     IIDC = jR.identifying_input_independent_canalizing_mutations(GExpanded, OutputNodes, Mapping, InverseMapping)\n",
    "#     UN = jR.identifying_input_unreachable_nodes(GExpanded, OutputNodes, Mapping, InverseMapping, InputConditions)\n",
    "    RN = jR.identifying_rn_mutations(GExpanded, mapping, inverse_mapping, input_nodes_ex, output_nodes_ex, input_conditions,\n",
    "                                     IORelation,\n",
    "                                     R0['ineffective_mutations'], R1['r1_mutations'])\n",
    "    \n",
    "    NodeList = set(read_nodes_dict.values())\n",
    "    NodeList.difference_update(input_nodes)\n",
    "    NodeList.difference_update(output_nodes)\n",
    "    C0, C1, C2, C3 = [], [], [], []\n",
    "    for NODE in NodeList:\n",
    "        negNODE = '~' + NODE\n",
    "        if R0['ineffective'][NODE] and R0['ineffective'][negNODE]:\n",
    "#             nodeClass = 'C0'\n",
    "            C0.append(NODE)\n",
    "        elif NODE in RN['rn_mutations']:\n",
    "            if RN['rn_mutations'][NODE] == 'R1':\n",
    "#                 nodeClass = 'C1'\n",
    "                C1.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "            else:\n",
    "#                 nodeClass = 'C2'\n",
    "                C2.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "        elif negNODE in RN['rn_mutations']:\n",
    "            if RN['rn_mutations'][negNODE] == 'R1':\n",
    "#                 nodeClass = 'C1'\n",
    "                C1.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "        else:\n",
    "#             nodeClass = 'C3'\n",
    "            C3.append(NODE)\n",
    "#             canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#             unreachable = UN['input_unreachable'][NODE]\n",
    "    \n",
    "\n",
    "    robustness_pa = rb.robustness_primary_attractor(g_read=g, state_num=2**sampling_num)\n",
    "    robustness_ip = rb.robustness_initial_perturbation(g_read=g, state_num=2**sampling_num)\n",
    "    \n",
    "    robustness = []\n",
    "    for key, val in robustness_pa.items():\n",
    "        robustness.append(val['oe'])\n",
    "        robustness.append(val['ko'])\n",
    "#     print(np.mean(robustness))\n",
    "    \n",
    "    LDOI_union = set()\n",
    "    for LDOI in LDOIs[0,:]:\n",
    "        LDOI_union = LDOI_union.union(LDOI)\n",
    "    LDOI_union = LDOI_union.union([mapping[x] for x in input_conditions.reshape((2*num_inputs,))])\n",
    "    GSub = nx.subgraph(GExpanded, LDOI_union)\n",
    "    io_count = 0\n",
    "    io_pathway_count = 0\n",
    "    for i in range(num_input_conditions):\n",
    "        # G_copied = G_expanded.copy()\n",
    "        BinaryBit = np.binary_repr(i, width=num_inputs)\n",
    "        InputCondition = [input_conditions[x, int(BinaryBit[x])] for x in range(num_inputs)]\n",
    "        # source_nodes = input_condition + constant_nodes\n",
    "        Sources = set([x for x in InputCondition])\n",
    "        # for node in source:\n",
    "        #     G_copied.remove_edges_from(list(G_copied.in_edges(node)))\n",
    "        #     G_copied.remove_edges_from(list(G_copied.in_edges(BDOId.Negation_in_expanded(node))))\n",
    "\n",
    "        Targets = set([x for x in IORelation[0, i]])\n",
    "        if len(Targets) > 0:\n",
    "            for s in Sources:\n",
    "                for t in Targets:\n",
    "                    if nx.has_path(G=g, source=inverse_read_nodes_dict[s.replace('~', '')], target=inverse_read_nodes_dict[t.replace('~', '')]):\n",
    "                        io_count += 1\n",
    "                        len_shortest_path = nx.shortest_path_length(G=g, source=inverse_read_nodes_dict[s.replace('~', '')], target=inverse_read_nodes_dict[t.replace('~', '')])\n",
    "                        for p in nx.all_simple_paths(G=g, source=inverse_read_nodes_dict[s.replace('~', '')], target=inverse_read_nodes_dict[t.replace('~', '')], cutoff=2*len_shortest_path):\n",
    "                            io_pathway_count += 1\n",
    "\n",
    "    if io_count == 0:\n",
    "        redundancy = -1\n",
    "    else:\n",
    "        redundancy = io_pathway_count/float(io_count)\n",
    "    \n",
    "    results = results.append({'network_idx': network_idx, 'size_of_network': len(g), 'num_link': len(g.edges), 'C0': len(C0), \n",
    "                            'C1': len(C1), 'C2': len(C2), 'C3': len(C3), 'robustness_pa': np.mean(robustness), 'robustness_ip': robustness_ip, \n",
    "                            'redundancy': redundancy}, ignore_index=True)\n",
    "    # , 'deterministic_io','nondeterministic_io' 추가 예정\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powered-groove",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only append a dict if ignore_index=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1f13a696728f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = results.append({'network_idx': network_idx, 'size_of_network': len(g), 'num_link': len(g.edges), 'C0': len(C0), \n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0;34m'C1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'robustness_pa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobustness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'robustness_ip'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrobustness_ip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             'redundancy': redundancy}, ignore_index=False)\n",
      "\u001b[0;32m~/miniconda3/envs/theor/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7944\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7945\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only append a dict if ignore_index=True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7946\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can only append a dict if ignore_index=True"
     ]
    }
   ],
   "source": [
    "results = results.append({'network_idx': network_idx, 'size_of_network': len(g), 'num_link': len(g.edges), 'C0': len(C0), \n",
    "                            'C1': len(C1), 'C2': len(C2), 'C3': len(C3), 'robustness_pa': np.mean(robustness), 'robustness_ip': robustness_ip, \n",
    "                            'redundancy': redundancy}, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../data/random_networks_er_kauffman_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
