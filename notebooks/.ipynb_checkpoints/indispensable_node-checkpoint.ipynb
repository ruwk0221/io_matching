{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moving-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))\n",
    "import jReversion as jR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, balanced_accuracy_score\n",
    "import networkx as nx\n",
    "from statannot import add_stat_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "herbal-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liu_driver_nodes(G):\n",
    "    from hopcroftkarp import HopcroftKarp\n",
    "    bipartite = {}\n",
    "    for node in G:\n",
    "        bipartite[str(node)+'*'] = set(G.successors(node))\n",
    "    \n",
    "    max_matching = HopcroftKarp(bipartite).maximum_matching()\n",
    "    matched_node = []\n",
    "    for value in max_matching.values():\n",
    "        if value in G.nodes:\n",
    "            matched_node.append(value)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return len(G) - len(matched_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proof-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indispensable_nodes(G, read_nodes):\n",
    "    original_number_unmatched_nodes = liu_driver_nodes(G)\n",
    "    mutated_number_unmatched_nodes = dict()\n",
    "    \n",
    "    for node in read_nodes:\n",
    "        Gcopy = G.copy()\n",
    "        Gcopy.remove_node(node)\n",
    "        mutated_number_unmatched_nodes[node] = liu_driver_nodes(Gcopy)\n",
    "        \n",
    "    indispensable = [read_nodes[x] for x, val in mutated_number_unmatched_nodes.items()\n",
    "                    if val > original_number_unmatched_nodes]\n",
    "    dispensable = [read_nodes[x] for x, val in mutated_number_unmatched_nodes.items()\n",
    "                    if val < original_number_unmatched_nodes]\n",
    "    neutral = [read_nodes[x] for x, val in mutated_number_unmatched_nodes.items()\n",
    "                    if val == original_number_unmatched_nodes]\n",
    "    \n",
    "    return{'indispensable': indispensable,\n",
    "          'dispensable': dispensable,\n",
    "          'neutral': neutral}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ahead-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkModel =['bortezomib',\n",
    "                # 'igvh',\n",
    "                'apoptosis',\n",
    "                # 'aurora',\n",
    "                'bt474_long',\n",
    "                'bt474_short',\n",
    "                # 'cd4t',\n",
    "                'colitis',\n",
    "                'death',\n",
    "                # 'egfr',\n",
    "                # 'erbb',\n",
    "                # 'fa_brca',\n",
    "                # 'fa_check',\n",
    "                'hcc1954_long',\n",
    "                'hcc1954_short',\n",
    "                'hgf',\n",
    "                'mammalian',\n",
    "                # 'mammalian_2006',\n",
    "                'mapk',\n",
    "                'oxidative',\n",
    "                # 'pro_inflammatory',\n",
    "                'fibroblasts',\n",
    "                'skbr3_long',\n",
    "                'skbr3_short',\n",
    "                'tlgl_2008',\n",
    "                'tlgl_2011',\n",
    "                # 'tlgl_2011_reduced',\n",
    "                # 'prostate',\n",
    "                'migration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satellite-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prefix, Suffix = 'n', 'n'\n",
    "TEMP = jR.cellcollective(networkModel[0], Prefix, Suffix, directory='../')\n",
    "\n",
    "BooleanRuleFileName = TEMP['BooleanRule_filename']\n",
    "network_name = TEMP['network_name']\n",
    "\n",
    "NumInputs = TEMP['num_inputs']\n",
    "NumInputConditions = TEMP['num_input_conditions']\n",
    "\n",
    "InputConditions = TEMP['input_conditions']\n",
    "\n",
    "OutputNodes = TEMP['output_nodes']\n",
    "InputNodes = TEMP['input_nodes']\n",
    "\n",
    "Mapping = TEMP['mapping']\n",
    "InverseMapping = TEMP['inverse_mapping']\n",
    "GRead = TEMP['Gread']\n",
    "ReadNodes = TEMP['read_nodes']\n",
    "\n",
    "integrated_data = pd.read_csv('../data/' + network_name + '_table_for_original_network.tsv', sep='\\t').sort_values(by='node').set_index('node')\n",
    "\n",
    "results = indispensable_nodes(GRead, ReadNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "graphic-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "indispensability = {}\n",
    "for node in results['indispensable']:\n",
    "    indispensability[node] = 'indispensable'\n",
    "for node in results['dispensable']:\n",
    "    indispensability[node] = 'dispensable'\n",
    "for node in results['neutral']:\n",
    "    indispensability[node] = 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "iraqi-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_data['indispensability'] = pd.Series(indispensability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "special-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "general-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Model in networkModel[1:]:\n",
    "    Prefix, Suffix = 'n', 'n'\n",
    "    TEMP = jR.cellcollective(Model, Prefix, Suffix, directory='../')\n",
    "\n",
    "    BooleanRuleFileName = TEMP['BooleanRule_filename']\n",
    "    network_name = TEMP['network_name']\n",
    "\n",
    "    NumInputs = TEMP['num_inputs']\n",
    "    NumInputConditions = TEMP['num_input_conditions']\n",
    "\n",
    "    InputConditions = TEMP['input_conditions']\n",
    "\n",
    "    OutputNodes = TEMP['output_nodes']\n",
    "    InputNodes = TEMP['input_nodes']\n",
    "    \n",
    "    Mapping = TEMP['mapping']\n",
    "    InverseMapping = TEMP['inverse_mapping']\n",
    "    GRead = TEMP['Gread']\n",
    "    ReadNodes = TEMP['read_nodes']\n",
    "    \n",
    "#     CutOffRange = [3, 4, 5, 6, 7]\n",
    "   \n",
    "\n",
    "    table_original_network = pd.read_csv('../data/' + network_name + '_table_for_original_network.tsv', sep='\\t').sort_values(by='node').set_index('node')\n",
    "    \n",
    "    results = indispensable_nodes(GRead, ReadNodes)\n",
    "    \n",
    "    indispensability = {}\n",
    "    for node in results['indispensable']:\n",
    "        indispensability[node] = 'indispensable'\n",
    "    for node in results['dispensable']:\n",
    "        indispensability[node] = 'dispensable'\n",
    "    for node in results['neutral']:\n",
    "        indispensability[node] = 'neutral'\n",
    "    table_original_network['indispensability'] = pd.Series(indispensability)\n",
    "    table_original_network['network'] = network_name\n",
    "    table_original_network.reset_index(inplace=True)\n",
    "    integrated_data = pd.concat([integrated_data, table_original_network], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
