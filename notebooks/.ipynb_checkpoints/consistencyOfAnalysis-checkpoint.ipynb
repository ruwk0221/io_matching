{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))\n",
    "import jReversion as jR\n",
    "from LDOI import BooleanDOI_processing as BDOIp\n",
    "from LDOI import qm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_regulator(g_read, mapping, input_nodes, output_nodes, p=0.2):\n",
    "    g_copy = g_read.copy()\n",
    "    input_nodes_idx = set([int(mapping[x].replace('n', '').replace('~','')) for x in input_nodes])\n",
    "    output_nodes_idx = set([int(mapping[x].replace('n', '').replace('~', '')) for x in output_nodes])\n",
    "    internal_nodes_idx = set(range(len(g_copy))).difference(input_nodes_idx.union(output_nodes_idx))\n",
    "\n",
    "    for ni in internal_nodes_idx.union(output_nodes_idx):\n",
    "        if np.random.rand() < p:\n",
    "            num_regulator = len(g_copy.nodes[ni]['update_nodes'])\n",
    "            temp = internal_nodes_idx.copy()\n",
    "            temp = temp.union(input_nodes_idx)\n",
    "            temp.discard(ni)\n",
    "            new_regulator = random.sample(temp, num_regulator)\n",
    "            g_copy.nodes[ni]['update_nodes'] = new_regulator\n",
    "            g_copy.remove_edges_from(list(g_copy.in_edges(ni)))\n",
    "            g_copy.add_edges_from(zip(new_regulator, np.tile([ni], num_regulator)))\n",
    "\n",
    "    return g_copy\n",
    "\n",
    "\n",
    "def randomize_target(g_read, mapping, input_nodes, output_nodes, p=0.2):\n",
    "    g_copy = g_read.copy()\n",
    "    input_nodes_idx = set([int(mapping[x].replace('n', '').replace('~','')) for x in input_nodes])\n",
    "    output_nodes_idx = set([int(mapping[x].replace('n', '').replace('~', '')) for x in output_nodes])\n",
    "    internal_nodes_idx = set(range(len(g_copy))).difference(input_nodes_idx.union(output_nodes_idx))\n",
    "\n",
    "    for ni in internal_nodes_idx.union(output_nodes_idx):\n",
    "        if np.random.rand() < p:\n",
    "            num_regulator = len(g_copy.nodes[ni]['update_nodes'])\n",
    "            temp = internal_nodes_idx.copy()\n",
    "            temp = temp.union(input_nodes_idx)\n",
    "            temp.discard(ni)\n",
    "            new_regulator = random.sample(temp, num_regulator)\n",
    "            # g_copy.nodes[ni]['update_nodes'] = new_regulator\n",
    "            g_copy.remove_edges_from(list(g_copy.out_edges(ni)))\n",
    "            g_copy.add_edges_from(zip(np.tile([ni], num_regulator), new_regulator))\n",
    "\n",
    "    return g_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prefix, Suffix = 'n', 'n'\n",
    "TEMP = jR.cellcollective(model, Prefix, Suffix)\n",
    "\n",
    "BooleanRuleFileName = TEMP['BooleanRule_filename']\n",
    "NetworkName = TEMP['network_name']\n",
    "\n",
    "NumInputs = TEMP['num_inputs']\n",
    "NumInputConditions = TEMP['num_input_conditions']\n",
    "\n",
    "InputConditions = TEMP['input_conditions']\n",
    "\n",
    "OutputNodes = TEMP['output_nodes']\n",
    "InputNodes = TEMP['input_nodes']\n",
    "\n",
    "# print(model + '- Nodes: ' + str(len(TEMP['Gread'])) + ' Input:' + str(len(InputNodes)) + ' Output:' + str(len(OutputNodes)))\n",
    "\n",
    "Mapping = TEMP['mapping']\n",
    "InverseMapping = TEMP['inverse_mapping']\n",
    "GRead = TEMP['Gread']\n",
    "ReadNodes = TEMP['read_nodes']\n",
    "\n",
    "GExpanded = BDOIp.Get_expanded_network(GRead, prefix=Prefix, suffix=Suffix)\n",
    "\n",
    "# integrated_data = pd.read_csv('../data/' + network_name + '_table_for_original_network.tsv', sep='\\t').sort_values(by='node').set_index('node')\n",
    "# table_original_network = table_original_network.sort_values(by='node')\n",
    "# ffl_test = pd.read_csv('../data/' + network_name + '_ffl_test.tsv', sep='\\t').sort_values(by='node').set_index('node')\n",
    "# canalizing_test = pd.read_csv('../data/' + network_name + '_canalizing_check_for_original_network.tsv', sep='\\t').sort_values(by='node').set_index('node')\n",
    "\n",
    "TempGIOW = jR.get_input_output_relation(GExpanded, mapping, inverse_mapping, input_conditions, output_nodes_ex,\n",
    "                                            constant_nodes=[])\n",
    "LDOIs = TempGIOW['LDOIs']\n",
    "GeneLDOIs = TempGIOW['gene_LDOIs']\n",
    "Conflicts = TempGIOW['conflicts']\n",
    "GeneConflicts = TempGIOW['gene_conflicts']\n",
    "IORelation = TempGIOW['io_relation']\n",
    "GRemained = TempGIOW['G_remained']\n",
    "\n",
    "R0 = jR.identifying_r0_mutations_ldoi(GExpanded, output_nodes_ex, mapping, inverse_mapping, input_conditions, IORelation)\n",
    "# DM = jR.identifying_disconnecting_mutations(GExpanded, InputNodes, OutputNodes, Mapping, InverseMapping)\n",
    "R1 = jR.identifying_r1_mutations_ldoi(GExpanded, output_nodes_ex, mapping, inverse_mapping, input_conditions, IORelation)\n",
    "#     IIDC = jR.identifying_input_independent_canalizing_mutations(GExpanded, OutputNodes, Mapping, InverseMapping)\n",
    "#     UN = jR.identifying_input_unreachable_nodes(GExpanded, OutputNodes, Mapping, InverseMapping, InputConditions)\n",
    "RN = jR.identifying_rn_mutations(GExpanded, mapping, inverse_mapping, input_nodes_ex, output_nodes_ex, input_conditions,\n",
    "                                 IORelation,\n",
    "                                 R0['ineffective_mutations'], R1['r1_mutations'])\n",
    "\n",
    "NodeList = set(read_nodes_dict.values())\n",
    "NodeList.difference_update(input_nodes)\n",
    "NodeList.difference_update(output_nodes)\n",
    "C0, C1, C2, C3 = [], [], [], []\n",
    "for NODE in NodeList:\n",
    "    negNODE = '~' + NODE\n",
    "    if R0['ineffective'][NODE] and R0['ineffective'][negNODE]:\n",
    "#             nodeClass = 'C0'\n",
    "        C0.append(NODE)\n",
    "    elif NODE in RN['rn_mutations']:\n",
    "        if RN['rn_mutations'][NODE] == 'R1':\n",
    "#                 nodeClass = 'C1'\n",
    "            C1.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "        else:\n",
    "#                 nodeClass = 'C2'\n",
    "            C2.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "    elif negNODE in RN['rn_mutations']:\n",
    "        if RN['rn_mutations'][negNODE] == 'R1':\n",
    "#                 nodeClass = 'C1'\n",
    "            C1.append(NODE)\n",
    "#                 canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#                 unreachable = UN['input_unreachable'][NODE]\n",
    "    else:\n",
    "#             nodeClass = 'C3'\n",
    "        C3.append(NODE)\n",
    "#             canalizing = IIDC['iid_canalizing'][NODE]\n",
    "#             unreachable = UN['input_unreachable'][NODE]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
